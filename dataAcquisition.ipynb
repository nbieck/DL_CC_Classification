{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aqcquisition - 17 and 102 Flowers Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute this notebook to download both datasets and have them prepared into the necessary folders for training, validation, and test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"data/17flowers\", exist_ok=True)\n",
    "os.makedirs(\"data/102flowers\", exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P data/17flowers https://thor.robots.ox.ac.uk/datasets/flowers-17/17flowers.tgz\n",
    "!wget -P data/17flowers https://thor.robots.ox.ac.uk/datasets/flowers-17/datasplits.mat\n",
    "!wget -P data/17flowers https://thor.robots.ox.ac.uk/datasets/flowers-17/trimaps.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P data/102flowers https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz\n",
    "!wget -P data/102flowers https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat\n",
    "!wget -P data/102flowers https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf data/17flowers/17flowers.tgz -C data/17flowers\n",
    "!tar -xzf data/102flowers/102flowers.tgz -C data/102flowers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm data/102flowers/102flowers.tgz\n",
    "!rm data/17flowers/17flowers.tgz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val/Test splits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pathlib\n",
    "import shutil\n",
    "import re  # Regex\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subfolders(path, labels):\n",
    "    \"\"\"\n",
    "    Create train/val/test subfolders with label folders.\n",
    "    \"\"\"\n",
    "    for split_name in [\"train/\", \"val/\", \"test/\"]:\n",
    "        for label in labels:\n",
    "            os.makedirs(path + split_name + label, exist_ok=True)\n",
    "    print(f\"All subfolders created at {path}.\")\n",
    "\n",
    "def move_images_to_subfolders_17f(path, labels, train_ids, val_ids, test_ids):\n",
    "    \"\"\"\n",
    "    Copy images from `path/jpg` to `path` subfolders train/val/test and their labels.\n",
    "    \"\"\"\n",
    "    src_path = path + \"jpg/\"\n",
    "    for filename in os.listdir(src_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            # Get the id of the image from its filename\n",
    "            file_id = int(re.findall(r'\\d+', filename)[0])\n",
    "\n",
    "            # Check which split the file belongs to\n",
    "            if file_id in train_ids:\n",
    "                split = \"train/\"\n",
    "            elif file_id in val_ids:\n",
    "                split = \"val/\"\n",
    "            elif file_id in test_ids:\n",
    "                split = \"test/\"\n",
    "            else:\n",
    "                print(f\"{filename} isn't associated with any splits.\")\n",
    "\n",
    "            # calculate the subfolder to move the image into\n",
    "            subfolder_id = (file_id-1) // 80  # File ids start from 1, so subtract one. 80 images per label\n",
    "            dst_path = path + split + labels[subfolder_id]\n",
    "\n",
    "            # move the image into the subfolder\n",
    "            shutil.copy(os.path.join(src_path, filename), os.path.join(dst_path, filename))\n",
    "    print(f\"Images copied successfully to {path} train/val/test subfolders.\")\n",
    "\n",
    "# move the images into the subfolders\n",
    "def move_images_to_subfolders_102f(path, labels, mat_labels, train_ids, val_ids, test_ids):\n",
    "    \"\"\"\n",
    "    Copy images from `path/jpg` their class subfolders.\n",
    "    \"\"\"\n",
    "    src_path = path + \"jpg/\"\n",
    "    for filename in os.listdir(src_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            # Get the id of the image from its filename\n",
    "            file_id = int(re.findall(r'\\d+', filename)[0])\n",
    "\n",
    "            # Get the class for the image\n",
    "            file_class = labels[mat_labels[file_id-1] - 1]\n",
    "\n",
    "            # Check which split the file belongs to\n",
    "            if file_id in train_ids:\n",
    "                split = \"train/\"\n",
    "            elif file_id in val_ids:\n",
    "                split = \"val/\"\n",
    "            elif file_id in test_ids:\n",
    "                split = \"test/\"\n",
    "            else:\n",
    "                print(f\"{filename} isn't associated with any splits.\")\n",
    "\n",
    "            dst_path = path + split + file_class\n",
    "\n",
    "            # Copy the image into the subfolder\n",
    "            shutil.copy(os.path.join(src_path, filename), os.path.join(dst_path, filename))\n",
    "    print(f\"Images copied successfully to {path}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize 17 Flowers into train/val/test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of class labels\n",
    "with open(\"17flowers_labels.txt\", \"r\") as f:\n",
    "    flower_labels_17 = [line.strip() for line in f]\n",
    "\n",
    "# Splits file\n",
    "mat = scipy.io.loadmat('./data/17flowers/datasplits.mat')\n",
    "\n",
    "# The image ids for each split\n",
    "train_ids = mat[\"trn1\"][0]\n",
    "val_ids = mat[\"val1\"][0]\n",
    "test_ids = mat[\"tst1\"][0]\n",
    "\n",
    "path_to_data = \"data/17flowers/\"\n",
    "\n",
    "create_subfolders(path_to_data, flower_labels_17)\n",
    "move_images_to_subfolders_17f(path_to_data, flower_labels_17, train_ids, val_ids, test_ids)\n",
    "\n",
    "# Split directories\n",
    "train_dir = pathlib.Path(path_to_data + \"train\")\n",
    "val_dir = pathlib.Path(path_to_data + \"val\")\n",
    "test_dir = pathlib.Path(path_to_data + \"test\")\n",
    "\n",
    "# Print useful information\n",
    "train_size = len(train_ids)\n",
    "val_size = len(val_ids)\n",
    "test_size = len(test_ids)\n",
    "train_count = len(list(train_dir.glob('*/*.jpg')))\n",
    "val_count = len(list(val_dir.glob('*/*.jpg')))\n",
    "test_count = len(list(test_dir.glob('*/*.jpg')))\n",
    "\n",
    "print(f\"Number of images at {path_to_data}: {train_count}/{train_size} (train), {val_count}/{val_size} (val), {test_count}/{test_size} (test)\")\n",
    "\n",
    "# Assertions\n",
    "assert train_count == train_size, f\"Expected {train_size} images, but {train_dir} only has {train_count}\"\n",
    "assert val_count == val_size, f\"Expected {train_size} images, but {val_dir} only has {val_count}\"\n",
    "assert test_count == test_size, f\"Expected {train_size} images, but {test_dir} only has {test_count}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize 102 Flowers into train/val/test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to the folder containing the images\n",
    "path_to_data = \"data/102flowers/\"\n",
    "\n",
    "# Load splits\n",
    "mat_splits = scipy.io.loadmat('./data/102flowers/setid.mat')\n",
    "train_ids = mat_splits[\"trnid\"][0]\n",
    "val_ids = mat_splits[\"valid\"][0]\n",
    "test_ids = mat_splits[\"tstid\"][0]\n",
    "\n",
    "# list of class labels\n",
    "with open(\"102flowers_labels.txt\", \"r\") as f:\n",
    "    flower_labels_102 = [line.strip() for line in f]\n",
    "\n",
    "# Class labels\n",
    "mat_labels = scipy.io.loadmat('./data/102flowers/imagelabels.mat')[\"labels\"][0]\n",
    "\n",
    "create_subfolders(path_to_data, flower_labels_102)\n",
    "move_images_to_subfolders_102f(path_to_data, flower_labels_102, mat_labels, train_ids, val_ids, test_ids) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color constancy dataset using fc4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to initialize and update the submodules:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "git init submodule\n",
    "git update\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"data/cc/17flowers\", exist_ok=True)\n",
    "os.makedirs(\"data/cc/102flowers\", exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17flowers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute FC4 to get the CC'ed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd thirdparty/fc4-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from fcn import FCN\n",
    "from config import *\n",
    "from utils import get_session\n",
    "\n",
    "\n",
    "def run_fc4(src_path, fcn):\n",
    "    for filename in os.listdir(src_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            path = 'data/17flowers/jpg/'+ filename\n",
    "            base = os.path.dirname(os.path.abspath('./../')) # 実行ファイルのディレクトリ名\n",
    "            target_path = os.path.join(base, path) # パスの連結\n",
    "            img = cv2.imread(target_path)\n",
    "            # reverse gamma correction for sRGB\n",
    "            img = (img / 255.0) ** 2.2 * 65536\n",
    "            images = [img]\n",
    "            fcn.test_external(images=images, fns=[target_path])\n",
    "\n",
    "\n",
    "with get_session() as sess:\n",
    "    fcn = FCN(sess=sess, name='../../pretrained_colorchecker/colorchecker_fold1and2.ckpt')\n",
    "    fcn.load_absolute('../../pretrained_colorchecker/colorchecker_fold1and2.ckpt')\n",
    "    src_path = '../../data/17flowers/jpg/'\n",
    "    run_fc4(src_path, fcn)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer files to the correct directory and clean-up: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv cc_outputs/* ../../data/17flowers/cc/jpg\n",
    "!rm -rf cc_outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 102 Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path =  '../../data/102flowers/jpg/'\n",
    "\n",
    "with get_session() as sess:\n",
    "    fcn = FCN(sess=sess, name='../../pretrained_colorchecker/colorchecker_fold1and2.ckpt')\n",
    "    fcn.load_absolute('../../pretrained_colorchecker/colorchecker_fold1and2.ckpt')\n",
    "    run_fc4(src_path, fcn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer and clean-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv cc_outputs/* ../../data/102flowers/cc/jpg\n",
    "!rm -rf cc_outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize the directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path_to_data_cc in [\"data/17flowers/cc/\", \"data/102flowers/cc/\"]:\n",
    "    create_subfolders(path_to_data_cc, flower_labels_17)\n",
    "    move_images_to_subfolders_17f(path_to_data_cc, flower_labels_17, train_ids, val_ids, test_ids)\n",
    "\n",
    "    train_dir_cc = pathlib.Path(path_to_data_cc + \"train\")\n",
    "    val_dir_cc = pathlib.Path(path_to_data_cc + \"val\")\n",
    "    test_dir_cc = pathlib.Path(path_to_data_cc + \"test\")\n",
    "\n",
    "    train_count_cc = len(list(train_dir_cc.glob('*/*.jpg')))\n",
    "    val_count_cc = len(list(val_dir_cc.glob('*/*.jpg')))\n",
    "    test_count_cc = len(list(test_dir_cc.glob('*/*.jpg')))\n",
    "\n",
    "    print(f\"Number of images at {path_to_data_cc}: {train_count_cc}/{train_size} (train), {val_count_cc}/{val_size} (val), {test_count_cc}/{test_size} (test)\")\n",
    "\n",
    "    assert train_count_cc == train_size, f\"Expected {train_size} images, but {train_dir_cc} only has {train_count_cc}\"\n",
    "    assert val_count_cc == val_size, f\"Expected {train_size} images, but {val_dir_cc} only has {val_count_cc}\"\n",
    "    assert test_count_cc == test_size, f\"Expected {train_size} images, but {test_dir_cc} only has {test_count_cc}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r data/17flowers/jpg data/102flowers/jpg data/17flowers/cc/jpg data/102flowers/cc/jpg\n",
    "!rm data/17flowers/datasplits.mat data/102flowers/setid.mat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
