{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-10 14:53:00.054209: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-10 14:53:00.098057: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "import pathlib\n",
        "import re  # Regex\n",
        "import time"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fabi implementation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This part will use the train/val/test splits provided in the dataseet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training  : 680 images.\n",
            "Validation: 340 images.\n",
            "Testing   : 340 images.\n"
          ]
        }
      ],
      "source": [
        "import scipy.io\n",
        "mat = scipy.io.loadmat('./data/17flowers/datasplits.mat')\n",
        "\n",
        "image_size = 224\n",
        "batch_size = 32\n",
        "epochs = 300\n",
        "\n",
        "# The image ids for each split\n",
        "train_ids = mat[\"trn1\"][0]\n",
        "val_ids = mat[\"val1\"][0]\n",
        "test_ids = mat[\"tst1\"][0]\n",
        "\n",
        "# The amount of images in each split\n",
        "train_size = len(train_ids)\n",
        "val_size = len(val_ids)\n",
        "test_size = len(test_ids)\n",
        "\n",
        "print(f\"Training  : {train_size} images.\")\n",
        "print(f\"Validation: {val_size} images.\")\n",
        "print(f\"Testing   : {test_size} images.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "create the 17 subfolders for each split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All subfolders created at data/17flowers/.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# list of class labels\n",
        "with open(\"17flowers_labels.txt\", \"r\") as f:\n",
        "    flower_labels = [line.strip() for line in f]\n",
        "\n",
        "# set the path to the folder containing the images\n",
        "path_to_data = \"data/17flowers/\"\n",
        "\n",
        "def create_subfolders(path):\n",
        "    \"\"\"\n",
        "    Create train/val/test subfolders with 17 subfolders each (1 for each label).\n",
        "    \"\"\"\n",
        "    for split_name in [\"train/\", \"val/\", \"test/\"]:\n",
        "        for label in flower_labels:\n",
        "            os.makedirs(path + split_name + label, exist_ok=True)\n",
        "    print(f\"All subfolders created at {path}.\")\n",
        "\n",
        "create_subfolders(path_to_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images copied successfully to data/17flowers/ test/train/val subfolders.\n"
          ]
        }
      ],
      "source": [
        "# move the images into the subfolders\n",
        "def move_images_to_subfolders(path):\n",
        "    \"\"\"\n",
        "    Copy images from `path/jpg` to `path` subfolders train/val/test and their labels.\n",
        "    \"\"\"\n",
        "    src_path = path + \"jpg/\"\n",
        "    for filename in os.listdir(src_path):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            # Get the id of the image from its filename\n",
        "            \n",
        "            file_id = int(re.findall(r'\\d+', filename)[0])\n",
        "            # file_id = int(filename[6:-4])\n",
        "\n",
        "            # Check which split the file belongs to\n",
        "            if file_id in train_ids:\n",
        "                split = \"train/\"\n",
        "            elif file_id in val_ids:\n",
        "                split = \"val/\"\n",
        "            elif file_id in test_ids:\n",
        "                split = \"test/\"\n",
        "            else:\n",
        "                print(f\"{filename} isn't associated with any splits.\")\n",
        "\n",
        "            # calculate the subfolder to move the image into\n",
        "            subfolder_id = (file_id-1) // 80  # File ids start from 1, so subtract one. 80 images per label\n",
        "            subfolder_name = path + split + flower_labels[subfolder_id]\n",
        "\n",
        "            # move the image into the subfolder\n",
        "            shutil.copy(os.path.join(src_path, filename), os.path.join(subfolder_name, filename))\n",
        "    print(f\"Images copied successfully to {path} test/train/val subfolders.\")\n",
        "\n",
        "\n",
        "move_images_to_subfolders(path_to_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images at data/17flowers/: 680/680 (train), 340/340 (val), 340/340 (test)\n"
          ]
        }
      ],
      "source": [
        "# Split directories\n",
        "train_dir = pathlib.Path(path_to_data + \"train\")\n",
        "val_dir = pathlib.Path(path_to_data + \"val\")\n",
        "test_dir = pathlib.Path(path_to_data + \"test\")\n",
        "\n",
        "# Image counts\n",
        "train_count = len(list(train_dir.glob('*/*.jpg')))\n",
        "val_count = len(list(val_dir.glob('*/*.jpg')))\n",
        "test_count = len(list(test_dir.glob('*/*.jpg')))\n",
        "\n",
        "print(f\"Number of images at {path_to_data}: {train_count}/{train_size} (train), {val_count}/{val_size} (val), {test_count}/{test_size} (test)\")\n",
        "\n",
        "# The number of images in each folder should be the same as the amount of ids provided by the datasplits.mat file\n",
        "assert train_count == train_size, f\"Expected {train_size} images, but {train_dir} only has {train_count}\"\n",
        "assert val_count == val_size, f\"Expected {train_size} images, but {val_dir} only has {val_count}\"\n",
        "assert test_count == test_size, f\"Expected {train_size} images, but {test_dir} only has {test_count}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 680 images belonging to 17 classes.\n",
            "Found 340 images belonging to 17 classes.\n",
            "Found 340 images belonging to 17 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  seed=123,\n",
        "  image_size=(image_size, image_size),\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  val_dir,\n",
        "  seed=123,\n",
        "  image_size=(image_size, image_size),\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  seed=123,\n",
        "  image_size=(image_size, image_size),\n",
        "  batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### cc dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_to_data_cc = \"data/17flowers/cc/\"\n",
        "create_subfolders(path_to_data_cc)\n",
        "\n",
        "train_dir_cc = pathlib.Path(path_to_data_cc + \"train\")\n",
        "val_dir_cc = pathlib.Path(path_to_data_cc + \"val\")\n",
        "test_dir_cc = pathlib.Path(path_to_data_cc + \"test\")\n",
        "\n",
        "train_count_cc = len(list(train_dir_cc.glob('*/*.jpg')))\n",
        "val_count_cc = len(list(val_dir_cc.glob('*/*.jpg')))\n",
        "test_count_cc = len(list(test_dir_cc.glob('*/*.jpg')))\n",
        "\n",
        "print(f\"Number of images at {path_to_data_cc}: {train_count_cc}/{train_size} (train), {val_count_cc}/{val_size} (val), {test_count_cc}/{test_size} (test)\")\n",
        "\n",
        "assert train_count_cc == train_size, f\"Expected {train_size} images, but {train_dir_cc} only has {train_count_cc}\"\n",
        "assert val_count_cc == val_size, f\"Expected {train_size} images, but {val_dir_cc} only has {val_count_cc}\"\n",
        "assert test_count_cc == test_size, f\"Expected {train_size} images, but {test_dir_cc} only has {test_count_cc}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds_cc = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_dir_cc,\n",
        "  seed=123,\n",
        "  image_size=(image_size, image_size),\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds_cc = tf.keras.utils.image_dataset_from_directory(\n",
        "  val_dir_cc,\n",
        "  seed=123,\n",
        "  image_size=(image_size, image_size),\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_ds_cc = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_dir_cc,\n",
        "  seed=123,\n",
        "  image_size=(image_size, image_size),\n",
        "  batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Base model function"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### base model for cc models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.applications import VGG16\n",
        "from processing.grey_world.cc_layers import WhitePatch\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        " \n",
        "\n",
        "def ccModel(cc_layers=None):\n",
        "    # Load the VGG model\n",
        "    vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "    # Freeze all the layers except for the last layer: \n",
        "    for layer in vgg_conv.layers[:-4]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Create the model\n",
        "    model = models.Sequential()\n",
        "    model.add(normalization_layer)\n",
        "\n",
        "    # model.add(tf.keras.layers.Rescaling(1./255))\n",
        "    if cc_layers != None:\n",
        "        # Add cc layers\n",
        "        model.add(cc_layers)\n",
        "    \n",
        "    # Add the vgg convolutional base model\n",
        "    model.add(vgg_conv)\n",
        "\n",
        "    # Add new layers\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1024, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(17, activation='softmax'))\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer=optimizers.RMSprop(lr=2e-4),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    # Build the model\n",
        "    model.build((None, image_size, image_size, 3))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "cc model for batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ccBachModel():\n",
        "    # Load the VGG model\n",
        "    vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "    # Freeze all the layers except for the last layer: \n",
        "    for layer in vgg_conv.layers[:-4]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Create the model\n",
        "    model = models.Sequential()\n",
        "    model.add(normalization_layer)\n",
        "\n",
        "    # model.add(tf.keras.layers.Rescaling(1./255))\n",
        "    model.add(tf.keras.layers.Conv2D(3, 5, padding=\"same\", input_shape=(image_size, image_size, 3)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "    # Add the vgg convolutional base model\n",
        "    model.add(vgg_conv)\n",
        "\n",
        "    # Add new layers\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1024, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(17, activation='softmax'))\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer=optimizers.RMSprop(lr=2e-4),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    # Build the model\n",
        "    model.build((None, image_size, image_size, 3))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def experiment(model, train_ds, val_ds, test_ds, n_trials=10):\n",
        "    metrics = {\n",
        "        \"train_time\": [],\n",
        "        \"test_time\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"train_loss\": [],\n",
        "        \"val_acc\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"test_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"history\": []\n",
        "    }\n",
        "\n",
        "    for i in range(n_trials):        \n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.RMSprop(lr=2e-4),\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        history = model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=epochs,\n",
        "            callbacks=[reduce_lr, early_stop],\n",
        "            verbose=0)\n",
        "        end_time = time.perf_counter()\n",
        "        training_time = end_time - start_time\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n",
        "        end_time = time.perf_counter()\n",
        "        test_time = end_time - start_time\n",
        "\n",
        "        metrics[\"train_time\"].append(training_time)\n",
        "        metrics[\"test_time\"].append(test_time)\n",
        "        metrics[\"train_acc\"].append(history.history[\"accuracy\"][-1])\n",
        "        metrics[\"train_loss\"].append(history.history[\"loss\"][-1])\n",
        "        metrics[\"val_acc\"].append(history.history[\"val_accuracy\"][-1])\n",
        "        metrics[\"val_loss\"].append(history.history[\"val_loss\"][-1])\n",
        "        metrics[\"test_acc\"].append(test_acc)\n",
        "        metrics[\"test_loss\"].append(test_loss)\n",
        "        metrics[\"history\"].append(history)\n",
        "    return metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from processing.grey_world.cc_layers import GreyWorld, WhitePatch, GreyEdge\n",
        "\n",
        "grey_world_layer = GreyWorld()\n",
        "white_patch_layer = WhitePatch()\n",
        "grey_edge_layer = GreyEdge()\n",
        "\n",
        "# Create new models\n",
        "model_base = ccModel()\n",
        "model_batch = ccBachModel()\n",
        "model_gw = ccModel(grey_world_layer)\n",
        "model_ge = ccModel(grey_edge_layer)\n",
        "model_wp = ccModel(white_patch_layer)\n",
        "model_fc4 = ccModel()\n",
        "\n",
        "# Run experiments\n",
        "n_trials = 1\n",
        "metrics = {}\n",
        "metrics[\"Base\"] = experiment(model_base, train_ds, val_ds, test_ds, n_trials=n_trials)\n",
        "metrics[\"BatchNorm\"] = experiment(model_batch, train_ds, val_ds, test_ds, n_trials=n_trials)\n",
        "metrics[\"GreyWorld\"] = experiment(model_gw, train_ds, val_ds, test_ds, n_trials=n_trials)\n",
        "metrics[\"GreyEdge\"] = experiment(model_ge, train_ds, val_ds, test_ds, n_trials=n_trials)\n",
        "metrics[\"WhitePatch\"] = experiment(model_wp, train_ds, val_ds, test_ds, n_trials=n_trials)\n",
        "metrics[\"FC4\"] = experiment(model_fc4, train_ds_cc, val_ds_cc, test_ds_cc, n_trials=n_trials)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "# Get the current timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
        "\n",
        "# Export data to Excel sheet\n",
        "dst_path = f\"./out/{timestamp}_experiments_17flowers.xlsx\"\n",
        "with pd.ExcelWriter(dst_path, engine='xlsxwriter',) as writer:\n",
        "    end_data = pd.concat({k: pd.DataFrame(v) for k, v in metrics.items()}, axis=0, names=[\"Algorithm\", \"Trial\"])\n",
        "    end_data.drop(\"history\", axis=1, inplace=True)\n",
        "    end_data.to_excel(writer, \"Final Data\", merge_cells=False)\n",
        "\n",
        "    for k, metric in metrics.items():\n",
        "        histories = metric[\"history\"]\n",
        "        algo_data = pd.concat({f\"{i}\": pd.DataFrame(history.history) for i, history in enumerate(histories)}, axis=1)\n",
        "        algo_data.to_excel(writer, f\"{k} History\", merge_cells=False)\n",
        "\n",
        "print(f\"Data saved to {dst_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
